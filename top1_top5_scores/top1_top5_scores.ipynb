{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUnwzEKe-_bg",
        "outputId": "ef851697-6ec2-486d-c3c6-8fc5b8910ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-vI-65HowiU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks/YapayZeka/Odev2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgWQ23R2H106"
      },
      "source": [
        "Rasgele 1000 soru üzerinden bir soruya en benzeyen 5 insan cevabını bulup gerçek cevaba göre top1 ve top5 başarılarını hesapladım.\n",
        "- Cosmos’daki BERT ve GPT modelleri kullanıldı.\n",
        "- 2 metnin temsilleri arasındaki açı kullanılarak benzerlik ölçümü yapıldı. (cosine_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DTku1kq_Z2M",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\n",
        "import torch\n",
        "\n",
        "# Veri setini yükleme\n",
        "data = pd.read_excel(\"soru_cevap.xlsx\").sample(n=1000, random_state=42)\n",
        "\n",
        "# Türkçe BERT modelini yükleme\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-base-bert-uncased\")\n",
        "model_bert = BertModel.from_pretrained(\"ytu-ce-cosmos/turkish-base-bert-uncased\")\n",
        "\n",
        "# Türkçe GPT-2 modelini yükleme\n",
        "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1\")\n",
        "model_gpt2 = GPT2Model.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1\")\n",
        "\n",
        "# Metin benzerliği fonksiyonu\n",
        "def calculate_similarity(text1, text2, tokenizer, model):\n",
        "    inputs1 = tokenizer(text1, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs2 = tokenizer(text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs1 = model(**inputs1)\n",
        "        outputs2 = model(**inputs2)\n",
        "    vector1 = torch.mean(outputs1.last_hidden_state, dim=1)\n",
        "    vector2 = torch.mean(outputs2.last_hidden_state, dim=1)\n",
        "    similarity = cosine_similarity(vector1, vector2)\n",
        "    return similarity.item()\n",
        "\n",
        "# En yakın 5 insan cevabını bulma fonksiyonu\n",
        "def find_top_5_human_answers(question, human_answers, tokenizer, model):\n",
        "    similarities = []\n",
        "    for answer in human_answers:\n",
        "        similarity = calculate_similarity(question, answer, tokenizer, model)\n",
        "        similarities.append(similarity)\n",
        "    top_5_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:5]\n",
        "    top_5_answers = [human_answers[i] for i in top_5_indices]\n",
        "    return top_5_answers\n",
        "\n",
        "# Top1 ve Top5 başarılarını hesaplama\n",
        "def calculate_accuracy(tokenizer, model):\n",
        "    top1_correct = 0\n",
        "    top5_correct = 0\n",
        "\n",
        "    # Tüm insan cevaplarını al\n",
        "    human_answers = list(data['insan cevabı'])\n",
        "    # Her bir satırda dolaş\n",
        "    for index, row in data.iterrows():\n",
        "        # Soruyu al\n",
        "        question = row['soru']\n",
        "\n",
        "        # En yakın 5 insan cevabını bul\n",
        "        top_5_human_answers = find_top_5_human_answers(question, human_answers, tokenizer, model)\n",
        "\n",
        "        # Top 1 doğruluk kontrolü\n",
        "        top_1_human_answer = top_5_human_answers[0]\n",
        "        if row['insan cevabı'] == top_1_human_answer:\n",
        "            top1_correct += 1\n",
        "            top5_correct += 1\n",
        "        # Top 5 doğruluk kontrolü\n",
        "        elif row['insan cevabı'] in top_5_human_answers:\n",
        "            top5_correct += 1\n",
        "\n",
        "    # Doğruluk oranlarını hesapla\n",
        "    top1_accuracy = top1_correct / len(data)\n",
        "    top5_accuracy = top5_correct / len(data)\n",
        "    return top1_accuracy, top5_accuracy\n",
        "\n",
        "# BERT modeli ile başarıyı hesapla\n",
        "top1_accuracy_bert, top5_accuracy_bert = calculate_accuracy(tokenizer_bert, model_bert)\n",
        "print(\"BERT ile Top1 Başarısı:\", top1_accuracy_bert)\n",
        "print(\"BERT ile Top5 Başarısı:\", top5_accuracy_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYBz4WKyBHE6"
      },
      "outputs": [],
      "source": [
        "# GPT-2 modeli ile başarıyı hesapla\n",
        "top1_accuracy_gpt2, top5_accuracy_gpt2 = calculate_accuracy(tokenizer_gpt2, model_gpt2)\n",
        "print(\"GPT-2 ile Top1 Başarısı:\", top1_accuracy_gpt2)\n",
        "print(\"GPT-2 ile Top5 Başarısı:\", top5_accuracy_gpt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0IlgoHdmPM8"
      },
      "source": [
        "1000 soru için çalıştırma çok uzun sürüyor, çıktıyı alamıyorum. 100 soru için devam edelim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tHztrIXmaIa",
        "outputId": "e0f45df2-f959-4031-f381-4ab045bd2fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT ile Top1 Başarısı: 0.6\n",
            "BERT ile Top5 Başarısı: 0.81\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\n",
        "import torch\n",
        "\n",
        "# Veri setini yükleme\n",
        "data = pd.read_excel(\"soru_cevap.xlsx\").sample(n=100, random_state=42)\n",
        "\n",
        "# Türkçe BERT modelini yükleme\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-base-bert-uncased\")\n",
        "model_bert = BertModel.from_pretrained(\"ytu-ce-cosmos/turkish-base-bert-uncased\")\n",
        "\n",
        "# Türkçe GPT-2 modelini yükleme\n",
        "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1\")\n",
        "model_gpt2 = GPT2Model.from_pretrained(\"ytu-ce-cosmos/turkish-gpt2-large-750m-instruct-v0.1\")\n",
        "\n",
        "# Metin benzerliği fonksiyonu\n",
        "def calculate_similarity(text1, text2, tokenizer, model):\n",
        "    inputs1 = tokenizer(text1, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs2 = tokenizer(text2, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs1 = model(**inputs1)\n",
        "        outputs2 = model(**inputs2)\n",
        "    vector1 = torch.mean(outputs1.last_hidden_state, dim=1)\n",
        "    vector2 = torch.mean(outputs2.last_hidden_state, dim=1)\n",
        "    similarity = cosine_similarity(vector1, vector2)\n",
        "    return similarity.item()\n",
        "\n",
        "# En yakın 5 insan cevabını bulma fonksiyonu\n",
        "def find_top_5_human_answers(question, human_answers, tokenizer, model):\n",
        "    similarities = []\n",
        "    for answer in human_answers:\n",
        "        similarity = calculate_similarity(question, answer, tokenizer, model)\n",
        "        similarities.append(similarity)\n",
        "    top_5_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:5]\n",
        "    top_5_answers = [human_answers[i] for i in top_5_indices]\n",
        "    return top_5_answers\n",
        "\n",
        "# Top1 ve Top5 başarılarını hesaplama\n",
        "def calculate_accuracy(tokenizer, model):\n",
        "    top1_correct = 0\n",
        "    top5_correct = 0\n",
        "\n",
        "    # Tüm insan cevaplarını al\n",
        "    human_answers = list(data['insan cevabı'])\n",
        "    # Her bir satırda dolaş\n",
        "    for index, row in data.iterrows():\n",
        "        # Soruyu al\n",
        "        question = row['soru']\n",
        "\n",
        "        # En yakın 5 insan cevabını bul\n",
        "        top_5_human_answers = find_top_5_human_answers(question, human_answers, tokenizer, model)\n",
        "\n",
        "        # Top 1 doğruluk kontrolü\n",
        "        top_1_human_answer = top_5_human_answers[0]\n",
        "        if row['insan cevabı'] == top_1_human_answer:\n",
        "            top1_correct += 1\n",
        "            top5_correct += 1\n",
        "        # Top 5 doğruluk kontrolü\n",
        "        elif row['insan cevabı'] in top_5_human_answers:\n",
        "            top5_correct += 1\n",
        "\n",
        "    # Doğruluk oranlarını hesapla\n",
        "    top1_accuracy = top1_correct / len(data)\n",
        "    top5_accuracy = top5_correct / len(data)\n",
        "    return top1_accuracy, top5_accuracy\n",
        "\n",
        "# BERT modeli ile başarıyı hesapla\n",
        "top1_accuracy_bert, top5_accuracy_bert = calculate_accuracy(tokenizer_bert, model_bert)\n",
        "print(\"BERT ile Top1 Başarısı:\", top1_accuracy_bert)\n",
        "print(\"BERT ile Top5 Başarısı:\", top5_accuracy_bert)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZebX8z66Fid",
        "outputId": "b5fd270d-520d-42a9-dc9b-d103cc8b611b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "# GPT-2 modeli ile başarıyı hesapla\n",
        "top1_accuracy_gpt2, top5_accuracy_gpt2 = calculate_accuracy(tokenizer_gpt2, model_gpt2)\n",
        "print(\"GPT-2 ile Top1 Başarısı:\", top1_accuracy_gpt2)\n",
        "print(\"GPT-2 ile Top5 Başarısı:\", top5_accuracy_gpt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5aAO4GoICVq"
      },
      "source": [
        "Rasgele 1000 soru üzerinden bir soruya en benzeyen 5 makine cevabını bulup gerçek cevaba göre top1 ve top5 başarılarını hesapladım.\n",
        "- Cosmos’daki BERT ve GPT modelleri kullanıldı.\n",
        "- 2 metnin temsilleri arasındaki açı kullanılarak benzerlik ölçümü yapıldı. (cosine_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhYELtfUDIK-"
      },
      "outputs": [],
      "source": [
        "# En yakın 5 makine cevabını bulma fonksiyonu\n",
        "def find_top_5_machine_answers(question, machine_answers, tokenizer, model):\n",
        "    similarities = []\n",
        "    for answer in machine_answers:\n",
        "        similarity = calculate_similarity(question, answer, tokenizer, model)\n",
        "        similarities.append(similarity)\n",
        "    top_5_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:5]\n",
        "    top_5_answers = [machine_answers[i] for i in top_5_indices]\n",
        "    return top_5_answers\n",
        "\n",
        "# Top1 ve Top5 başarılarını hesaplama (makine cevapları için)\n",
        "def calculate_machine_accuracy(tokenizer, model):\n",
        "    top1_correct = 0\n",
        "    top5_correct = 0\n",
        "\n",
        "    # Tüm makine cevaplarını al\n",
        "    machine_answers = list(data['makine cevabı'])\n",
        "    # Her bir satırı dolaş\n",
        "    for index, row in data.iterrows():\n",
        "        question = row['soru']\n",
        "        top_5_machine_answers = find_top_5_machine_answers(question, machine_answers, tokenizer, model)\n",
        "\n",
        "        # Top 1 doğruluk kontrolü\n",
        "        top_1_machine_answer = top_5_machine_answers[0]\n",
        "        if row['makine cevabı'] == top_1_machine_answer:\n",
        "            top1_correct += 1\n",
        "            top5_correct += 1\n",
        "        # Top 5 doğruluk kontrolü\n",
        "        elif row['makine cevabı'] in top_5_machine_answers:\n",
        "            top5_correct += 1\n",
        "    top1_accuracy = top1_correct / len(data)\n",
        "    top5_accuracy = top5_correct / len(data)\n",
        "    return top1_accuracy, top5_accuracy\n",
        "\n",
        "# BERT modeli ile başarıyı hesapla (makine cevapları için)\n",
        "top1_accuracy_bert_machine, top5_accuracy_bert_machine = calculate_machine_accuracy(tokenizer_bert, model_bert)\n",
        "print(\"BERT ile Makine Cevapları İçin Top1 Başarısı:\", top1_accuracy_bert_machine)\n",
        "print(\"BERT ile Makine Cevapları İçin Top5 Başarısı:\", top5_accuracy_bert_machine)\n",
        "\n",
        "# GPT-2 modeli ile başarıyı hesapla (makine cevapları için)\n",
        "top1_accuracy_gpt2_machine, top5_accuracy_gpt2_machine = calculate_machine_accuracy(tokenizer_gpt2, model_gpt2)\n",
        "print(\"GPT-2 ile Makine Cevapları İçin Top1 Başarısı:\", top1_accuracy_gpt2_machine)\n",
        "print(\"GPT-2 ile Makine Cevapları İçin Top5 Başarısı:\", top5_accuracy_gpt2_machine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujjadzXI4vA"
      },
      "source": [
        "Rasgele 1000 soru üzerinden bir insan cevabına en benzeyen 5 soruyu bulup gerçek soruya göre top1 ve top5 başarılarını hesapladım.\n",
        "- Cosmos’daki BERT ve GPT modelleri kullanıldı.\n",
        "- 2 metnin temsilleri arasındaki açı kullanılarak benzerlik ölçümü yapıldı. (cosine_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXjfpjz2LLW2"
      },
      "outputs": [],
      "source": [
        "# En yakın 5 soruyu bulma fonksiyonu\n",
        "def find_top_5_questions(answer, questions, tokenizer, model):\n",
        "    similarities = []\n",
        "    for question in questions:\n",
        "        similarity = calculate_similarity(question, answer, tokenizer, model)\n",
        "        similarities.append(similarity)\n",
        "    top_5_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:5]\n",
        "    top_5_questions = [questions[i] for i in top_5_indices]\n",
        "    return top_5_questions\n",
        "\n",
        "# Top1 ve Top5 başarılarını hesaplama (insan cevaplarına göre)\n",
        "def calculate_question_accuracy(tokenizer, model):\n",
        "    top1_correct = 0\n",
        "    top5_correct = 0\n",
        "\n",
        "    # Tüm soruları al\n",
        "    questions = list(data['soru'])\n",
        "    # Her bir satırı dolaş\n",
        "    for index, row in data.iterrows():\n",
        "        answer = row['insan cevabı']\n",
        "        top_5_questions = find_top_5_questions(answer, questions, tokenizer, model)\n",
        "\n",
        "        # Top 1 doğruluk kontrolü\n",
        "        if row['soru'] == top_5_questions[0]:\n",
        "            top1_correct += 1\n",
        "\n",
        "        # Top 5 doğruluk kontrolü\n",
        "        if row['soru'] in top_5_questions:\n",
        "            top5_correct += 1\n",
        "    top1_accuracy = top1_correct / len(data)\n",
        "    top5_accuracy = top5_correct / len(data)\n",
        "    return top1_accuracy, top5_accuracy\n",
        "\n",
        "# BERT modeli ile başarıyı hesapla (insan cevaplarına göre)\n",
        "top1_accuracy_bert_question, top5_accuracy_bert_question = calculate_question_accuracy(tokenizer_bert, model_bert)\n",
        "print(\"BERT ile İnsan Cevaplarına Göre Top1 Başarısı:\", top1_accuracy_bert_question)\n",
        "print(\"BERT ile İnsan Cevaplarına Göre Top5 Başarısı:\", top5_accuracy_bert_question)\n",
        "\n",
        "# GPT-2 modeli ile başarıyı hesapla (insan cevaplarına göre)\n",
        "top1_accuracy_gpt2_question, top5_accuracy_gpt2_question = calculate_question_accuracy(tokenizer_gpt2, model_gpt2)\n",
        "print(\"GPT-2 ile İnsan Cevaplarına Göre Top1 Başarısı:\", top1_accuracy_gpt2_question)\n",
        "print(\"GPT-2 ile İnsan Cevaplarına Göre Top5 Başarısı:\", top5_accuracy_gpt2_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57lS2FM2JLII"
      },
      "source": [
        "Rasgele 1000 soru üzerinden bir makine cevabına en benzeyen 5 soruyu bulup gerçek soruya göre top1 ve top5 başarılarını hesapladım.\n",
        "- Cosmos’daki BERT ve GPT modelleri kullanıldı.\n",
        "- 2 metnin temsilleri arasındaki açı kullanılarak benzerlik ölçümü yapıldı. (cosine_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nup3cHXkJUvC"
      },
      "outputs": [],
      "source": [
        "# En yakın 5 soruyu bulma fonksiyonu (makine cevapları için)\n",
        "def find_top_5_questions(answer, questions, tokenizer, model):\n",
        "    similarities = []\n",
        "    for question in questions:\n",
        "        similarity = calculate_similarity(question, answer, tokenizer, model)\n",
        "        similarities.append(similarity)\n",
        "    top_5_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:5]\n",
        "    top_5_questions = [questions[i] for i in top_5_indices]\n",
        "    return top_5_questions\n",
        "\n",
        "# Top1 ve Top5 başarılarını hesaplama (makine cevapları için)\n",
        "def calculate_question_accuracy_machine(tokenizer, model):\n",
        "    top1_correct = 0\n",
        "    top5_correct = 0\n",
        "\n",
        "    # Tüm soruları al\n",
        "    questions = list(data['soru'])\n",
        "    # Her bir satırı dolaş\n",
        "    for index, row in data.iterrows():\n",
        "        answer = row['makine cevabı']\n",
        "        top_5_questions = find_top_5_questions(answer, questions, tokenizer, model)\n",
        "\n",
        "        # Top 1 doğruluk kontrolü\n",
        "        if row['soru'] == top_5_questions[0]:\n",
        "            top1_correct += 1\n",
        "\n",
        "        # Top 5 doğruluk kontrolü\n",
        "        if row['soru'] in top_5_questions:\n",
        "            top5_correct += 1\n",
        "    top1_accuracy = top1_correct / len(data)\n",
        "    top5_accuracy = top5_correct / len(data)\n",
        "    return top1_accuracy, top5_accuracy\n",
        "\n",
        "# BERT modeli ile başarıyı hesapla (makine cevapları için)\n",
        "top1_accuracy_bert_question, top5_accuracy_bert_question = calculate_question_accuracy(tokenizer_bert, model_bert)\n",
        "print(\"BERT ile Makine Cevaplarına Göre Top1 Başarısı:\", top1_accuracy_bert_question)\n",
        "print(\"BERT ile Makine Cevaplarına Göre Top5 Başarısı:\", top5_accuracy_bert_question)\n",
        "\n",
        "# GPT-2 modeli ile başarıyı hesapla (makine cevapları için)\n",
        "top1_accuracy_gpt2_question, top5_accuracy_gpt2_question = calculate_question_accuracy(tokenizer_gpt2, model_gpt2)\n",
        "print(\"GPT-2 ile Makine Cevaplarına Göre Top1 Başarısı:\", top1_accuracy_gpt2_question)\n",
        "print(\"GPT-2 ile Makine Cevaplarına Göre Top5 Başarısı:\", top5_accuracy_gpt2_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVlPRXM5gQYj"
      },
      "source": [
        "Rasgele 1000 soru üzerinden:\n",
        "Bir soruya en benzeyen 5 insan cevabını bulup gerçek cevaba göre top1 ve top5 başarılarını hesapladık.\n",
        "Bir soruya en benzeyen 5 makine cevabını bulup gerçek cevaba göre top1 ve top5 başarılarını hesapladık.\n",
        "Bir insan cevabına en benzeyen 5 soruyu bulup gerçek soruya göre top1 ve top5 başarılarını hesapladık.\n",
        "Bir makine cevabına en benzeyen 5 soruyu bulup gerçek soruya göre top1 ve top5 başarılarını hesapladık.\n",
        "\n",
        "Her birinde de BERT ve GPT ile top 1 ve top 5 başarıları  hesapladık.\n",
        "\n",
        "Şimdi ise soru, insan cevabı, makine cevabı bu temsiller üzerine tsne uygulanarak 2 boyutta türlerine göre renklendirilerek görselleştirelim.\n",
        "Tsne görselleştirilmesinde bert vektörleri için ayrı, gpt vektörleri için ayrı görsel oluşturalım. Ve türlerine göre renklendirmekte istenilen \"soru\", \"insan cevabı\" ve \"makine cevabı\" sütünları için farklı renkler atayalım.\n",
        "Yani 2 farklı görsel yapalım, 3 ayrı renk olsun her birinde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co_6jEJVkQT3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Veri setini yükleme\n",
        "data = pd.read_excel(\"soru_cevap.xlsx\").sample(n=1000, random_state=42)\n",
        "\n",
        "# BERT ve GPT modeliyle vektörleri çıkaralım\n",
        "bert_vectors = []\n",
        "gpt_vectors = []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    question = row['soru']\n",
        "    human_answer = row['insan cevabı']\n",
        "    machine_answer = row['makine cevabı']\n",
        "\n",
        "    # BERT modelinden vektörleri çıkar\n",
        "    inputs_bert = tokenizer_bert(question, human_answer, machine_answer, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs_bert = model_bert(**inputs_bert)\n",
        "    bert_vector = torch.mean(outputs_bert.last_hidden_state, dim=1).squeeze().numpy()\n",
        "    bert_vectors.append(bert_vector)\n",
        "\n",
        "    # GPT-2 modelinden vektörleri çıkar\n",
        "    inputs_gpt2 = tokenizer_gpt2(question, human_answer, machine_answer, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs_gpt2 = model_gpt2(**inputs_gpt2)\n",
        "    gpt2_vector = torch.mean(outputs_gpt2.last_hidden_state, dim=1).squeeze().numpy()\n",
        "    gpt_vectors.append(gpt2_vector)\n",
        "\n",
        "# TSNE ile boyut indirgeme\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "bert_tsne = tsne.fit_transform(bert_vectors)\n",
        "gpt_tsne = tsne.fit_transform(gpt_vectors)\n",
        "\n",
        "# Veri çerçevesine TSNE sonuçlarını ekleme\n",
        "data['bert_tsne_x'] = bert_tsne[:, 0]\n",
        "data['bert_tsne_y'] = bert_tsne[:, 1]\n",
        "data['gpt_tsne_x'] = gpt_tsne[:, 0]\n",
        "data['gpt_tsne_y'] = gpt_tsne[:, 1]\n",
        "\n",
        "# Görselleştirme\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# BERT TSNE görseli\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(data['bert_tsne_x'], data['bert_tsne_y'], c=data['soru'], cmap='viridis', label='Soru')\n",
        "plt.scatter(data['bert_tsne_x'], data['bert_tsne_y'], c=data['insan cevabı'], cmap='plasma', label='İnsan Cevabı')\n",
        "plt.scatter(data['bert_tsne_x'], data['bert_tsne_y'], c=data['makine cevabı'], cmap='inferno', label='Makine Cevabı')\n",
        "plt.title('BERT TSNE Görseli')\n",
        "plt.xlabel('TSNE X')\n",
        "plt.ylabel('TSNE Y')\n",
        "plt.legend()\n",
        "\n",
        "# GPT-2 TSNE görseli\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(data['gpt_tsne_x'], data['gpt_tsne_y'], c=data['soru'], cmap='viridis', label='Soru')\n",
        "plt.scatter(data['gpt_tsne_x'], data['gpt_tsne_y'], c=data['insan cevabı'], cmap='plasma', label='İnsan Cevabı')\n",
        "plt.scatter(data['gpt_tsne_x'], data['gpt_tsne_y'], c=data['makine cevabı'], cmap='inferno', label='Makine Cevabı')\n",
        "plt.title('GPT-2 TSNE Görseli')\n",
        "plt.xlabel('TSNE X')\n",
        "plt.ylabel('TSNE Y')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}